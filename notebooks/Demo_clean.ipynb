{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5030e1e4",
   "metadata": {},
   "source": [
    "# AutoAssist — Multi‑Agent DIY Auto Repair Workflow (Demo)\n",
    "\n",
    "**Course:** CIS 568 (Spring 2026)  \n",
    "**Project:** AutoAssist — guided DIY auto repair workflows with human‑in‑the‑loop safety checks.\n",
    "\n",
    "## What this demo shows\n",
    "- How a vague symptom becomes a **structured question**\n",
    "- Web/knowledge **research & grounding**\n",
    "- **Verification** (fit/safety checks + confidence)\n",
    "- A **beginner‑friendly step‑by‑step plan** with parts/tools checklist\n",
    "- **Escalation** / “when NOT to DIY” behavior\n",
    "\n",
    "## How to run\n",
    "1. Run cells top‑to‑bottom\n",
    "2. Enter a sample issue (e.g., “2015 Honda Civic brake squeal”)\n",
    "3. Review the agent outputs and the final repair plan\n",
    "\n",
    "> Tip: Keep v1 scope to common, low‑to‑moderate repairs (battery, brakes, lights, filters, spark plugs, OBD‑II codes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Exe77DNhFVz"
   },
   "source": [
    "8) **System design**\n",
    "\n",
    "Provide the system design at a high level. Describe the workflow: inputs → model/agent actions → outputs → human checks/escalation paths. What data will you need, and where will you get it from? How you will evaluate performance, monitor issues, handle failure modes, and use fallbacks? If relevant, briefly call out latency and cost-to-serve assumptions.\n",
    "\n",
    "9) **Live demo**\n",
    "\n",
    "Your demo should support your value proposition (not just “look what ChatGPT can do”). It should be tied directly to your primary use case and should make the before/after obvious. Any demo format is fine (for instance, agent/workflow demo, clickable prototype demo, data/model feasibility demo), but it should demonstrate a realistic scenario. Ideally, the demo shows the user journey, the key moment where AI creates the step-change, and a failure mode when the system is uncertain (guardrails, escalation, human-in-the-loop, etc). Do not use confidential customer data in the demo unless you have explicit permission. Keep a video of your demo handy in case you run into technical issues with the live demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kvf-wPIjh1Vb"
   },
   "source": [
    "#Installing and Getting the AI Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDma7-p3gxFg",
    "outputId": "6441c878-43f4-447c-ccf0-c496cf33609f"
   },
   "outputs": [],
   "source": [
    "# Installing groq\n",
    "!pip install aisuite openai groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JG4hJz6hw3z"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "import aisuite\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "\n",
    "# read the API_KEYs from Colab Secrets and expose it as an env variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
    "\n",
    "# create the clients\n",
    "openai_client = OpenAI()\n",
    "groq_client = Groq()\n",
    "aisuite_client = aisuite.Client()\n",
    "\n",
    "# select the models you want to use\n",
    "OPENAI_MODEL= \"gpt-4.1-mini\"\n",
    "AISUITE_OPENAI_MODEL = \"openai:\"+OPENAI_MODEL\n",
    "GROQ_MODEL = \"llama-3.3-70b-versatile\"\n",
    "AISUITE_GROQ_MODEL = \"groq:\"+GROQ_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ekew-ZfNiEAl"
   },
   "outputs": [],
   "source": [
    "# Used to clean up the output's display\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def show(title, text):\n",
    "    display(HTML(f\"\"\"\n",
    "     <h4>{title}</h4>\n",
    "     <div style=\"white-space: pre-wrap; padding-left: 24px;\">{text}</div>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A5jPP80iLSo"
   },
   "outputs": [],
   "source": [
    "# This code cell allows OpenAI to search the web so it can return information after it's training date\n",
    "import json\n",
    "\n",
    "def openai_web_search(query: str):\n",
    "  \"\"\"\n",
    "    Perform a web search using OpenAI's built-in web_search tool\n",
    "    and return raw results.\n",
    "  \"\"\"\n",
    "  resp = openai_client.responses.create(\n",
    "      model=OPENAI_MODEL,\n",
    "      input=query,\n",
    "      tools=[{\"type\": \"web_search\"}],\n",
    "  )\n",
    "  return json.loads(resp.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfkN8O4riXV8"
   },
   "outputs": [],
   "source": [
    "# This code cell is used to create an run_openai_query function\n",
    "\n",
    "# used for wall-clock timing for request\n",
    "import time\n",
    "\n",
    "# run the system/user prompt using OpenAI API, invoke tools as needed;\n",
    "# return response and query details (usage stats and tools invoked)\n",
    "def run_openai_query(system_prompt, user_prompt, tools=[]):\n",
    "  \"\"\"\n",
    "    Execute the query, print the prompt, the response, and detailed usage stats.\n",
    "    Supports tools.\n",
    "  \"\"\"\n",
    "\n",
    "  # start the time before the API call\n",
    "  start_time = time.time()\n",
    "\n",
    "  # make chat-completions request thro aisuite, routed to OpenAI-backed model\n",
    "  completion = aisuite_client.chat.completions.create(\n",
    "      model=AISUITE_OPENAI_MODEL, # OpenAI-backed model\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_prompt}, # system sets global behavior/instructions\n",
    "           {\"role\": \"user\", \"content\": user_prompt} # user contains the actual task/prompt\n",
    "      ],\n",
    "      tools=tools,\n",
    "      max_turns=3,\n",
    "  )\n",
    "\n",
    "  # compute end-to-end wall-clock time for API request\n",
    "  elapsed_time = time.time() - start_time\n",
    "\n",
    "  # response\n",
    "  response = completion.choices[0].message.content.strip()\n",
    "\n",
    "  # usage stats\n",
    "  query_details = {}\n",
    "  query_details[\"prompt_tokens\"]=completion.usage.prompt_tokens\n",
    "  query_details[\"completion_tokens\"]=completion.usage.completion_tokens\n",
    "  query_details[\"total_tokens\"]=completion.usage.total_tokens\n",
    "  if hasattr(completion.usage, 'total_time'):\n",
    "    query_details[\"total_time\"]=f\"{completion.usage.total_time:.2f}s\"\n",
    "  else:\n",
    "    query_details[\"total_time\"]=f\"{elapsed_time:.2f}s\"\n",
    "\n",
    "  # tools invoked\n",
    "  tools_invoked=[]\n",
    "  messages = completion.choices[0].intermediate_messages\n",
    "  for m in messages or []:\n",
    "    if hasattr(m, \"tool_calls\") and m.tool_calls:\n",
    "      for t in m.tool_calls:\n",
    "        tools_invoked.append(t.function.name)\n",
    "  query_details[\"tools_invoked\"]=tools_invoked\n",
    "\n",
    "  return response, query_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lisjYPvNiiVC"
   },
   "outputs": [],
   "source": [
    "# This code cell is used to create run_groq_query function\n",
    "\n",
    "# used for wall-clock timing for request\n",
    "import time\n",
    "\n",
    "# run the system/user prompt using OpenAI API; DOES NOT support tools;\n",
    "# return response and query details (usage stats and tools invoked)\n",
    "def run_groq_query(system_prompt, user_prompt):\n",
    "  \"\"\"\n",
    "    Execute the query, print the prompt, the response, and detailed usage stats.\n",
    "    Does not support tools.\n",
    "  \"\"\"\n",
    "\n",
    "  # start the time before the API call\n",
    "  start_time = time.time()\n",
    "\n",
    "  # make chat-completions request thro aisuite, routed to Groq-backed model\n",
    "  completion = aisuite_client.chat.completions.create(\n",
    "      model=AISUITE_GROQ_MODEL, # Groq-backed model\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_prompt}, # system sets global behavior/instructions\n",
    "           {\"role\": \"user\", \"content\": user_prompt} # user contains the actual task/prompt\n",
    "      ],\n",
    "      max_turns=1,\n",
    "  )\n",
    "\n",
    "  # compute end-to-end wall-clock time for API request\n",
    "  elapsed_time = time.time() - start_time\n",
    "\n",
    "  # response\n",
    "  response = completion.choices[0].message.content.strip()\n",
    "\n",
    "  # usage stats\n",
    "  query_details = {}\n",
    "  query_details[\"prompt_tokens\"]=completion.usage.prompt_tokens\n",
    "  query_details[\"completion_tokens\"]=completion.usage.completion_tokens\n",
    "  query_details[\"total_tokens\"]=completion.usage.total_tokens\n",
    "  if hasattr(completion.usage, 'total_time'):\n",
    "    query_details[\"total_time\"]=f\"{completion.usage.total_time:.2f}s\"\n",
    "  else:\n",
    "    query_details[\"total_time\"]=f\"{elapsed_time:.2f}s\"\n",
    "\n",
    "  # tools invoked\n",
    "  tools_invoked=[]\n",
    "  messages = completion.choices[0].intermediate_messages\n",
    "  for m in messages or []:\n",
    "    if hasattr(m, \"tool_calls\") and m.tool_calls:\n",
    "      for t in m.tool_calls:\n",
    "        tools_invoked.append(t.function.name)\n",
    "  query_details[\"tools_invoked\"]=tools_invoked\n",
    "\n",
    "  return response, query_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqX_rhK4jS-h"
   },
   "source": [
    "#Creating Pieces of the AgenticAI Workflow\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMieOyfO2J-L"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Creating the Questioner\n",
    "# Takes in the user's general quetion about car maintence & car model\n",
    "#########################################################################\n",
    "\n",
    "def questioner (question: str):\n",
    "\n",
    "  # questioner system prompt\n",
    "  questioner_system_prompt = (\n",
    "    f\"\"\"\n",
    "    You are a questioner agent for answering the user's question about car maintenance.\n",
    "    Your job is to rephrase the question that the user asks, not to write prose.\n",
    "    Be clear, concise, and structured.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # questioner user prompt\n",
    "  questioner_user_prompt = (\n",
    "    f\"\"\"\n",
    "    Rephrase question:{question}\n",
    "    Make sure that the question has the:\n",
    "      1. the specific question that the user has about the car maintenance\n",
    "      2. the car model\n",
    "    Return the question that the user asked only.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # use Groq (no tools) to create a question\n",
    "  question_2, query_details = run_groq_query(questioner_system_prompt, questioner_user_prompt)\n",
    "\n",
    "  # return the question\n",
    "  return question_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_7Bgjyj4cYh"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Creating the Researcher\n",
    "# Takes in the user's general quetion about car maintence & car model and researches the topic\n",
    "#########################################################################\n",
    "\n",
    "def researcher (question_2:str):\n",
    "\n",
    "  # researcher system prompt\n",
    "  researcher_system_prompt = (\n",
    "    f\"\"\"\n",
    "    You are a research for car maintenance.\n",
    "    Use web search to find accurate, up-to-date information.\n",
    "    Return factual notes with sources.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # research user prompt\n",
    "  researcher_user_prompt = (\n",
    "    f\"\"\"\n",
    "    Maitenance plan (outline + checklist):{question_2}\n",
    "    For each outline section:\n",
    "      1. Provide instruction to fix the question that the user has about their car model\n",
    "      2. If needed, provide parts that are needed in order to fix the question the user has and make sure it relates to their car model\n",
    "    Return concise research notes only.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # use OpenAI (with web_search) to do the research\n",
    "  research, query_details = run_openai_query(researcher_system_prompt, researcher_user_prompt, tools=[openai_web_search])\n",
    "\n",
    "  return research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzFnvqxw5n6v"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Creating the Verifier\n",
    "# Looks at the research that the Research did and double checks if it's correct\n",
    "#########################################################################\n",
    "\n",
    "def verifier (question_2: str, research: str):\n",
    "\n",
    "# ****************** INDENTED THE SECTION FROM HERE ******************\n",
    "  # verifier system prompt\n",
    "  verifier_system_prompt = (\n",
    "    f\"\"\"\n",
    "    You are a critical verifier.\n",
    "    Your job is to evaluate and suggest improvements, not to rewrite the content.\n",
    "    Be specific and constructive.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # verifier user prompt\n",
    "  verifier_user_prompt = (\n",
    "    f\"\"\"\n",
    "    Original re-written question from user:{question_2}\n",
    "    Research from researcher:{research}\n",
    "    Evaluate on: clarity and accuracy (given the research).\n",
    "    Provide:\n",
    "      1. A 1-5 score for each category\n",
    "      2. Specific, actionable improvement suggestions\n",
    "      3. Check if the repairs mentioned ties back to the model the user specified\n",
    "    Do not rewrite the research.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # use Groq (no tools) provide feedback on the feedback\n",
    "  feedback, query_details = run_groq_query(verifier_system_prompt, verifier_user_prompt)\n",
    "\n",
    "  return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8H_73zLc6tnk"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Creating the Planner\n",
    "# Takes in the research and verifier to create a plan for the user\n",
    "#########################################################################\n",
    "\n",
    "def planner (research: str, feedback: str):\n",
    "\n",
    "  # planner system prompt\n",
    "  planner_system_prompt = (\n",
    "    f\"\"\"\n",
    "    You are a car repair worker telling a client how to repair a car.\n",
    "    Keep in mind that the client doesn't know much about car repairs.\n",
    "    Create a list of instructions to repair the car as well as the tools.\n",
    "    Preserve the original intent and outline unless told otherwise.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # planner user prompt\n",
    "  planner_user_prompt = (\n",
    "    f\"\"\"\n",
    "    Original blog draft:{research}\n",
    "    Editor feedback:{feedback}\n",
    "    Revise the research using the feedback.\n",
    "    Return the full revised instructions and tools for car maintenance.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # use OpenAI (no tools) creat the instructions\n",
    "  instructions, query_details = run_openai_query(planner_system_prompt, planner_user_prompt, tools=[])\n",
    "\n",
    "  return instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5exMKACd9hA6"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Creating the Assistant Researcher\n",
    "# Takes in any question the user has about the instructions\n",
    "#########################################################################\n",
    "\n",
    "def assistant (instructions: str, followUp: str):\n",
    "\n",
    "  # assistant system prompt\n",
    "  assistant_system_prompt = (\n",
    "    f\"\"\"\n",
    "    You are a car repair worker.\n",
    "    Use web search to find accurate, up-to-date information.\n",
    "    Return factual notes with sources.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # assistant user prompt\n",
    "  assistant_user_prompt = (\n",
    "    f\"\"\"\n",
    "    Original instructions:{instructions}\n",
    "    User's follow-up question:{followUp}\n",
    "    For each outline section:\n",
    "      1. Provide information about the section that the user has a follow-up question about.\n",
    "      2. If needed, explain how the part is needed for the repair.\n",
    "    Return concise research notes only.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # use OpenAI (no tools) create the follow-up answer\n",
    "  answer, query_details = run_openai_query(assistant_system_prompt, assistant_user_prompt, tools=[openai_web_search])\n",
    "\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH5HKLv48ZMt"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Creating the Explainer Researcher\n",
    "# Creates the output of the response\n",
    "#########################################################################\n",
    "\n",
    "def explainer (answer: str):\n",
    "\n",
    "  # assistant system prompt\n",
    "  explainer_system_prompt = (\n",
    "    f\"\"\"\n",
    "    You are a car repair worker explaining any concept the user doesn't know about the instructions.\n",
    "    Keep in mind that the user doesn't know much about car repairs.\n",
    "    Answer the question the user has about the instructions.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # explainer user prompt\n",
    "  explainer_user_prompt = (\n",
    "    f\"\"\"\n",
    "    Follow-up answer:{answer}\n",
    "    Double check if the feedback is correct.\n",
    "    Return an easy to understand but informative response to answer the user's question.\n",
    "    \"\"\"\n",
    "  )\n",
    "\n",
    "  # use OpenAI (no tools) create the follow-up answer\n",
    "  explanation, query_details = run_openai_query(explainer_system_prompt, explainer_user_prompt, tools=[])\n",
    "\n",
    "  return explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0sgAG1c-yQm"
   },
   "source": [
    "Using Gradio to create the Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "NPMfF1E--3-e",
    "outputId": "e69a1f1c-e4b9-4448-c35f-1570c43b69d2"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# building the UI\n",
    "with gr.Blocks(title=\"AgenticAI Car Repair Instructions\") as app:\n",
    "\n",
    "    # Agent 1 : Questioner\n",
    "    # *****************************************************\n",
    "    # Textbox to provide the userQuest input\n",
    "    question = gr.Textbox(label=\"Quesiton\", placeholder=\"Enter your car repair question as well as the car model.\")\n",
    "\n",
    "    # Button that triggers the questioner when clicked\n",
    "    submit_userQuest_btn = gr.Button(\"Submit Question!\")\n",
    "\n",
    "    # Textbox to display the (editable) questioner output\n",
    "    question_2 = gr.Textbox(label=\"The question being asked\", lines=10)\n",
    "\n",
    "    # The question is editable by user\n",
    "    submit_userQuest_btn.click(fn=questioner, inputs=[question], outputs=[question_2])\n",
    "\n",
    "    # Button that triggers the researcher when clicked\n",
    "    submit_question_btn = gr.Button(\"Research the Repair\")\n",
    "\n",
    "\n",
    "    # Agent 2 : Researcher\n",
    "    # *****************************************************\n",
    "    # Textbox to display the (editable) researcher output\n",
    "    research = gr.Textbox(label=\"Information from Researcher (editable)\", lines=10)\n",
    "\n",
    "    # When the submit question button is clicked, call researcher\n",
    "    submit_question_btn.click(fn=researcher, inputs=[question_2], outputs=[research])\n",
    "\n",
    "    # Button that triggers the Verifier when clicked\n",
    "    submit_research_btn = gr.Button(\"Double Check the Research\")\n",
    "\n",
    "\n",
    "    # Agent 3 : Verifier\n",
    "    # *****************************************************\n",
    "    # Textbox to display the (editable) verifier output\n",
    "    feedback = gr.Textbox(label=\"Verified Information (editable)\", lines=10)\n",
    "\n",
    "    # When the submit research button is clicked, call verifier\n",
    "    submit_research_btn.click(fn=verifier, inputs=[question_2, research], outputs=[feedback])\n",
    "\n",
    "    # Button that triggers the Planner when clicked\n",
    "    submit_feedback_btn = gr.Button(\"Create Repair Instructions\")\n",
    "\n",
    "\n",
    "    # Agent 4 : Planner\n",
    "    # *****************************************************\n",
    "    # Textbox to display the (editable) Planner instructions\n",
    "    instructions = gr.Textbox(label=\"Instructions (editable)\", lines=10)\n",
    "\n",
    "    # When the submit feedback button is clicked, call Planner\n",
    "    submit_feedback_btn.click(fn=planner, inputs=[research, feedback], outputs=[instructions])\n",
    "\n",
    "\n",
    "    # Agent 5 : Assist Researcher\n",
    "    # *****************************************************\n",
    "    # Textbox to provide the followUp input\n",
    "    followUp = gr.Textbox(label=\"Follow-up Quesiton?\", placeholder=\"Any follow-up questions about the Instructions provided?.\")\n",
    "\n",
    "    # Button that triggers the assistant when clicked\n",
    "    submit_followUp_btn = gr.Button(\"Submit Follow-Up Question!\")\n",
    "\n",
    "\n",
    "    # Textbox to display the (editable) assistant output\n",
    "    answer = gr.Textbox(label=\"Quick Research on the Follow-Up Question\", lines=10)\n",
    "\n",
    "    # The response is editable by user\n",
    "    submit_followUp_btn.click(fn=assistant, inputs=[instructions, followUp], outputs=[answer])\n",
    "\n",
    "    # Button that triggers the researcher when clicked\n",
    "    submit_answer_btn = gr.Button(\"Get Explanation\")\n",
    "\n",
    "# Can take Agent 6 out\n",
    "\n",
    "    # Agent 6 : Explainer\n",
    "    # *****************************************************\n",
    "    # Textbox to display Explainer output\n",
    "    explanation = gr.Textbox(label=\"Explanation on the Follow-Up Question\", lines=10)\n",
    "\n",
    "    # When the submit feedback button is clicked, call Explainer\n",
    "    submit_answer_btn.click(fn=explainer, inputs=[answer], outputs=[explanation])\n",
    "\n",
    "# Start the Gradio web application\n",
    "app.launch()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
